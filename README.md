# Crypto Market Analytics â€” Data Engineering Pet Project

This is a **Data Engineering pet project** designed to simulate a real-world streaming + batch data platform for cryptocurrency market analytics.  
The goal is to practice end-to-end skills: ingestion, contracts, streaming (Kafka), orchestration (Airflow), data modeling, and BI dashboards.

---

## ğŸš€ Project Overview
- **Source:** [CoinGecko API](https://www.coingecko.com/en/api/documentation) `/coins/markets`
- **Assets:** Top 10 cryptocurrencies  
  (BTC, ETH, XRP, BNB, SOL, DOGE, TRX, ADA, HYPE, SUI)
- **Pipeline:**
  - Producer polls API every 5 minutes â†’ pushes to Kafka (`crypto.prices.raw`)
  - Validation against JSON Schema (v1.1), invalid events â†’ DLQ
  - Consumers process RT metrics & alerts
  - Airflow DAGs orchestrate batch ingestion into Lake/DWH
  - BI dashboards for exploration and monitoring

---

## ğŸ“‚ Repository Structure
.
â”œâ”€â”€ contracts/                # Event schemas & examples
â”‚   â”œâ”€â”€ event_crypto_price.schema.json
â”‚   â””â”€â”€ EXAMPLES/
â”‚       â”œâ”€â”€ example_btc.json
â”‚       â””â”€â”€ example_eth.json
â”œâ”€â”€ docs/                     # Documentation
â”‚   â”œâ”€â”€ PROJECT_CHARTER.md
â”‚   â”œâ”€â”€ KPI_SLO_SLA.md
â”‚   â”œâ”€â”€ DATA_SCOPE.md
â”‚   â”œâ”€â”€ NFR.md
â”‚   â”œâ”€â”€ RISKS_ASSUMPTIONS.md
â”‚   â”œâ”€â”€ ESTIMATES.md
â”‚   â””â”€â”€ DECISIONS.md
â”œâ”€â”€ infra/                    # Infrastructure setup
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â””â”€â”€ .env.sample
â”œâ”€â”€ producer/                 # API fetcher + Kafka producer
â”‚   â””â”€â”€ main.py
â””â”€â”€ README.md

---

## ğŸ“‘ Documentation

- [Project Charter](./docs/PROJECT_CHARTER.md) â€” goal, scope, use cases, in/out.  
- [KPI / SLO / SLA](./docs/KPI_SLO_SLA.md) â€” freshness, latency, availability, data quality.  
- [Data Scope](./docs/DATA_SCOPE.md) â€” assets, polling frequency, fields, example payload.  
- [Non-Functional Requirements](./docs/NFR.md) â€” retention, formats, UTC, security.  
- [Risks & Assumptions](./docs/RISKS_ASSUMPTIONS.md) â€” risks and mitigations.  
- [Estimates](./docs/ESTIMATES.md) â€” effort and resource estimates for all epics.  
- [Decisions (ADR)](./docs/DECISIONS.md) â€” 10+ key architecture decisions.  

---

## ğŸ› ï¸ Infrastructure

- **Streaming:** Apache Kafka (with ZooKeeper)  
- **Orchestration:** Apache Airflow  
- **Storage:** MinIO (S3-compatible) + Postgres (stretch: ClickHouse)  
- **Contracts:** JSON Schema (v1.1) in `/contracts`  
- **Visualization:** Superset or Metabase (optional)  

---

## ğŸ“Š Data Flow

1. **Ingestion:** Producer polls CoinGecko API â†’ Kafka (`crypto.prices.raw`).  
2. **Validation:** JSON Schema ensures contract compliance; invalid events â†’ `crypto.prices.dlq`.  
3. **Streaming:** Consumers calculate RT metrics, anomalies, alerts.  
4. **Batch:** Airflow DAGs write Bronze â†’ Silver â†’ Gold in Lake/DWH.  
5. **BI:** Dashboards query Gold layer.

---

## âš¡ Quick Start

---

âœ… Status
	â€¢	Epic 1 (Foundations & Contracts)
	â€¢	Epic 2 (Streaming Ingestion)
	â€¢	Epic 3 (Batch Ingestion & Orchestration)
	â€¢	Epic 4 (Data Warehouse & Modeling)
	â€¢	Epic 5 (Real-Time Analytics & Alerts)
	â€¢	Epic 6 (Visualization & BI)
	â€¢	Epic 7 (ML & Forecasting â€” Stretch)
 
---
ğŸ“Œ Notes
	â€¢	Data volume: ~90k events/month (~200 MB).
	â€¢	Polling interval: 5 minutes (batched for 10 coins).
	â€¢	Unique event key: (coin_id, vs_currency, ts_event).

---
